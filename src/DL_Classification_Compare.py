# -*- coding: utf-8 -*-
"""OGNet_Pankaj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14vvKeJ-S-Se8I26MJGwlUJlumoOKZ8tN
"""

!pip install tensorflow codecarbon keras_tuner

from google.colab import drive
drive.mount('/content/drive')

#%% Import Libraries
import tensorflow as tf
from tensorflow.keras.applications import (
    DenseNet121, ResNet50, VGG16, InceptionV3, MobileNetV2, EfficientNetB0,
    NASNetMobile, Xception, InceptionResNetV2, ResNet152V2
)
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from kerastuner.tuners import RandomSearch
import logging

# Enable mixed precision training for efficiency (optional, requires GPU with Tensor Cores)
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# ----------------------------------------------------------------------------
# Paths to datasets (adjust these paths to your environment)
# ----------------------------------------------------------------------------
train_csv = '/content/drive/MyDrive/Colab Notebooks/OGNetDevelopmentData/train.csv'
val_csv   = '/content/drive/MyDrive/Colab Notebooks/OGNetDevelopmentData/val.csv'
test_csv  = '/content/drive/MyDrive/Colab Notebooks/OGNetDevelopmentData/test.csv'
image_dir = '/content/drive/MyDrive/Colab Notebooks/OGNetDevelopmentData'

# Output directory
output_dir = '/content/drive/MyDrive/Colab Notebooks/OGNetDevelopmentData/results'
os.makedirs(output_dir, exist_ok=True)
hyperparams_file = os.path.join(output_dir, 'best_hyperparams.csv')

# Configure logging
logging.basicConfig(filename='training_log.log', level=logging.INFO)

###############################################################################
# Oversampling Helper Function
###############################################################################
def oversample_df(df, target_column="Target"):
    """
    Oversample the minority class so that it has the same number
    of instances as the majority class (simple random oversampling).
    """
    df_majority = df[df[target_column] == '0']
    df_minority = df[df[target_column] == '1']

    # Random oversample the minority class to match the majority
    df_minority_oversampled = df_minority.sample(len(df_majority),
                                                 replace=True,
                                                 random_state=42)

    # Combine & shuffle
    df_oversampled = pd.concat([df_majority, df_minority_oversampled], axis=0)
    df_oversampled = df_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)
    return df_oversampled

###############################################################################
# Load Datasets
###############################################################################
def load_datasets(train_csv=train_csv, val_csv=val_csv,
                  test_csv=test_csv, image_dir=image_dir):
    train_df = pd.read_csv(train_csv)
    val_df   = pd.read_csv(val_csv)
    test_df  = pd.read_csv(test_csv)

    for df in [train_df, val_df, test_df]:
        df['Target'] = df['Target'].astype(str)
        df['Image_Path'] = df['Image_Path'].apply(lambda x: os.path.join(image_dir, x))

    print("Length of train_df =", len(train_df))
    print("Length of val_df   =", len(val_df))
    print("Length of test_df  =", len(test_df))

    return train_df, val_df, test_df

train_df, val_df, test_df = load_datasets()

# (Optional) Oversample Train
train_df = oversample_df(train_df, target_column="Target")
# val_df = oversample_df(val_df, target_column="Target")  # If you want

###############################################################################
# TF Data Pipeline
###############################################################################
IMAGE_SIZE = (128, 128)  # Adjust for speed/accuracy trade-off

def parse_image(filepath, label):
    """Read an image from filepath and preprocess."""
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, IMAGE_SIZE)
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

def augment_image(image, label):
    """Apply random augmentations for training."""
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    return image, label

def create_dataset(df, batch_size=32, shuffle_data=True, augment=False):
    """Create a tf.data.Dataset from a DataFrame."""
    filepaths = df['Image_Path'].values
    labels = df['Target'].astype(int).values

    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))
    ds = ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)

    if augment:
        ds = ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)
    if shuffle_data:
        ds = ds.shuffle(buffer_size=len(df))

    ds = ds.batch(batch_size)
    # Cache to memory if it fits, otherwise remove or change to .cache(filename)
    ds = ds.cache()
    ds = ds.prefetch(tf.data.AUTOTUNE)
    return ds

# Create tf.data Datasets
train_ds = create_dataset(train_df, batch_size=32, shuffle_data=True, augment=True)
val_ds   = create_dataset(val_df,   batch_size=32, shuffle_data=False, augment=False)
test_ds  = create_dataset(test_df,  batch_size=32, shuffle_data=False, augment=False)

###############################################################################
# Helper Functions for Plotting
###############################################################################
import matplotlib.pyplot as plt
import seaborn as sns

def plot_and_save(history, model_name, output_dir):
    # Plot Loss
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'{model_name} - Training & Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(output_dir, f'{model_name}_loss_curve.png'))
    plt.close()

    # Plot Accuracy
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title(f'{model_name} - Training & Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.savefig(os.path.join(output_dir, f'{model_name}_accuracy_curve.png'))
    plt.close()

def plot_confusion_matrix(y_true, y_pred, model_name, output_dir):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f'{model_name} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.savefig(os.path.join(output_dir, f'{model_name}_confusion_matrix.png'))
    plt.close()

###############################################################################
# Build Model Function (for Keras Tuner)
###############################################################################
def build_model(hp, base_model_class, input_shape):
    """
    Keras Tuner model-building function.
    Reduced search space to speed up training.
    """
    base_model = base_model_class(weights='imagenet', include_top=False, input_shape=input_shape)

    # Freeze or unfreeze the base model
    train_base = hp.Boolean('train_base', default=False)
    for layer in base_model.layers:
        layer.trainable = train_base

    x = GlobalAveragePooling2D()(base_model.output)
    dropout_rate = hp.Float('dropout_rate', min_value=0.3, max_value=0.5, step=0.1)
    x = Dropout(dropout_rate)(x)
    dense_units = hp.Int('dense_units', min_value=64, max_value=128, step=64)
    x = Dense(dense_units, activation='relu')(x)
    predictions = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    return model

###############################################################################
# Train and Evaluate Model
###############################################################################
def train_and_evaluate_model(base_model_class, model_name, input_shape,
                             train_ds, val_ds, test_ds, output_dir, test_df):
    model_output_dir = os.path.join(output_dir, model_name)
    os.makedirs(model_output_dir, exist_ok=True)

    # Load or create a hyperparameters DataFrame
    if os.path.exists(hyperparams_file):
        hyperparams_df = pd.read_csv(hyperparams_file)
    else:
        hyperparams_df = pd.DataFrame(columns=['Model', 'dropout_rate', 'dense_units', 'train_base'])

    # Check if we already have best hyperparams for this model
    if not hyperparams_df.empty and model_name in hyperparams_df['Model'].values:
        best_params = hyperparams_df[hyperparams_df['Model'] == model_name].iloc[0]
        dropout_rate = best_params['dropout_rate']
        dense_units  = int(best_params['dense_units'])
        train_base   = bool(best_params['train_base'])

        # Build a model with these best params
        base_model = base_model_class(weights='imagenet', include_top=False, input_shape=input_shape)
        for layer in base_model.layers:
            layer.trainable = train_base

        x = GlobalAveragePooling2D()(base_model.output)
        x = Dropout(dropout_rate)(x)
        x = Dense(dense_units, activation='relu')(x)
        predictions = Dense(1, activation='sigmoid')(x)

        best_model = Model(inputs=base_model.input, outputs=predictions)
        best_model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
    else:
        # Hyperparameter tuning using Keras Tuner with fewer trials/epochs for speed
        tuner = RandomSearch(
            lambda hp: build_model(hp, base_model_class, input_shape),
            objective='val_accuracy',
            max_trials=3,  # reduced for speed
            executions_per_trial=1,
            directory=model_output_dir,
            project_name=f'{model_name}_tuning'
        )

        # Fewer epochs during tuning to speed it up
        tuner.search(train_ds, epochs=5, validation_data=val_ds, verbose=1)

        # Remove num_models argument for compatibility with older Keras Tuner
        best_model = tuner.get_best_models()[0]
        best_hp = tuner.get_best_hyperparameters()[0]

        best_params = {
            'Model': model_name,
            'dropout_rate': best_hp.get('dropout_rate'),
            'dense_units': best_hp.get('dense_units'),
            'train_base': best_hp.get('train_base')
        }

        hyperparams_df = pd.concat([hyperparams_df, pd.DataFrame([best_params])])
        hyperparams_df.to_csv(hyperparams_file, index=False)

    # Define callbacks
    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    checkpoint = ModelCheckpoint(
        filepath=os.path.join(model_output_dir, f'{model_name}_checkpoint.h5'),
        save_best_only=True,
        monitor='val_loss',
        mode='min'
    )
    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)

    # Final training with moderate epochs
    history = best_model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=8,
        callbacks=[early_stopping, checkpoint, lr_scheduler],
        verbose=1
    )

    # Evaluate on the test set (loss & accuracy)
    test_loss, test_accuracy = best_model.evaluate(test_ds, verbose=1)

    # Gather test set predictions
    predictions = best_model.predict(test_ds)
    # Retrieve the true labels from test_ds
    y_true_list = []
    for _, labels in test_ds:
        y_true_list.extend(labels.numpy())
    y_true = np.array(y_true_list, dtype=int)

    # -----------------------------------------------------
    # Find the best threshold for the highest F1 score
    # -----------------------------------------------------
    thresholds = np.linspace(0, 1, 101)  # 0.00, 0.01, ..., 1.00
    best_threshold = 0.5
    best_f1_value = 0.0

    for thresh in thresholds:
        y_pred_thresh = (predictions > thresh).astype(int).flatten()
        f1_val = f1_score(y_true, y_pred_thresh)
        if f1_val > best_f1_value:
            best_f1_value = f1_val
            best_threshold = thresh

    # Compute final predictions at the best threshold
    y_pred_best = (predictions > best_threshold).astype(int).flatten()

    # Final metrics at the best threshold
    precision_best = precision_score(y_true, y_pred_best)
    recall_best    = recall_score(y_true, y_pred_best)

    # Plot training curves
    plot_and_save(history, model_name, model_output_dir)
    # Plot confusion matrix with the best threshold
    plot_confusion_matrix(y_true, y_pred_best, f'{model_name}_best_threshold', model_output_dir)

    # Create a CSV file with per-image predictions on the test set
    filepaths_test = test_df['Image_Path'].values
    base_names = [os.path.basename(fp) for fp in filepaths_test]

    predictions_df = pd.DataFrame({
        'Image Name': base_names,
        'Prediction Probability': predictions.flatten(),
        'Predicted Label': y_pred_best,
        'Actual Label': y_true,
        'Chosen Threshold': [best_threshold] * len(y_true)
    })
    predictions_df.to_csv(os.path.join(model_output_dir, f'{model_name}_test_predictions.csv'), index=False)

    # Save overall model results
    results = {
        'Model': model_name,
        'Test Loss': test_loss,
        'Test Accuracy': test_accuracy,
        'Best Threshold': best_threshold,
        'F1 Score': best_f1_value,
        'Precision': precision_best,
        'Recall': recall_best
    }
    pd.DataFrame([results]).to_csv(os.path.join(model_output_dir, f'{model_name}_results.csv'), index=False)

    logging.info(f"Completed training and evaluation for {model_name} with best threshold {best_threshold:.3f}")
    tf.keras.backend.clear_session()
    return results

###############################################################################
# Main: Run Training for Multiple Models
###############################################################################
models_to_compare = [
    ("DenseNet121",        DenseNet121),
    ("ResNet50",           ResNet50),
    ("VGG16",              VGG16),
    ("InceptionV3",        InceptionV3),
    ("MobileNetV2",        MobileNetV2),
    ("EfficientNetB0",     EfficientNetB0),
    ("NASNetMobile",       NASNetMobile),
    ("Xception",           Xception),
    ("InceptionResNetV2",  InceptionResNetV2),
    ("ResNet152V2",        ResNet152V2)
]

results = []
for model_name, model_class in models_to_compare:
    print(f"\nTraining and evaluating {model_name}...")
    metrics = train_and_evaluate_model(
        base_model_class=model_class,
        model_name=model_name,
        input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),
        train_ds=train_ds,
        val_ds=val_ds,
        test_ds=test_ds,
        output_dir=output_dir,
        test_df=test_df
    )
    results.append(metrics)

results_df = pd.DataFrame(results)
results_df.to_csv(os.path.join(output_dir, 'overall_model_comparison_results.csv'), index=False)

print("\nFinal Results:")
print(results_df)


#%%

#%%
import base64
from openai import OpenAI
import re
client = OpenAI()
import json
import pandas as pd

# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


prompt = """
### Task: Circular Storage Tank/Tank Farm Detection  
You are a highly advanced AI model trained for **aerial image classification** tasks, specifically to detect **circular Storage Tanks/Tank Farms** in oil and gas facilities.

---
### Classification Criteria
Determine if a given aerial image contains **at least 8 circular Storage Tanks/Tank Farms** and return your conclusion in **JSON format**, including:

1. **Predicted Label**  
   - `1` → **Circular Storage Tanks/Tank Farms are present, with at least 8 tanks visible, and the facility is NOT near a densely populated residential area.**  
   - `0` → **Fewer than 8 circular tanks are visible OR no circular tanks are detected.**
   
2. **Reason**  
   - A detailed explanation of the classification, including visual cues (e.g., shape, arrangement, shadows, and typical oil and gas storage layouts).

---
### Step-by-Step Analysis
1. **Identify Circular Storage Tanks/Tank Farms**
   - Scan for **circular top views** characteristic of **oil and gas storage tanks**.
   - Focus on **clusters** of tanks, usually appearing in groups.
   - Tanks typically have **large footprints, distinct round edges, and visible shadows**.

2. **Minimum Tank Count Requirement**
   - **Count the circular tanks** in the image.
   - If there are **fewer than 8 tanks**, classify the image as `0` (Not a storage tank farm).
   - If there are **8 or more circular tanks**, continue to the next step.

3. **Ignore Other Features**
   - Only count **circular** storage tanks.
   - Ignore **rectangular, irregular, or small cylindrical** tanks.
   - Do not classify based on processing units, pipelines, jetties, or non-oil-related industrial structures.

4. **Rule Out Confusions**
   - **Agricultural Silos or Water Treatment Tanks** may look circular but are typically found in different contexts.
   - **Chemical Plants** often contain various vessels but may not meet the required tank count.
   - **Residential Areas often have water storage tanks**, which should not be considered oil and gas storage.

5. **Assess Visibility and Confidence**
   - Consider image clarity (resolution, angle, lighting).
   - If 8+ circular tanks are clearly visible , classify confidently as `1`.
   - If fewer than 8 tanks are visible, classify as `0`.

---
### Output Format
Your response must be a valid **JSON** object with the following format:

#### Example 1: **Circular Storage Tanks/Tank Farms Detected (≥8 tanks, NOT near residential area)**
```json
{
  "Predicted Label": 1,
  "Reason": "At least 8 circular storage tanks with large footprints are clearly identifiable. The facility is located in an industrial or remote area."
}

####Example 2: No Circular Storage Tanks/Tank Farms Present (<8 tanks)
```json
{
  "Predicted Label": 0,
  "Reason": "Only 4 circular tanks detected, which is below the threshold of 8. Other industrial structures do not match oil and gas storage characteristics."
}


"""

# Function to process an image and get a response from the model
def classify_image(image_path):
    # Encode image to base64
    base64_image = encode_image(image_path)
    
    # Try up to 5 times before giving up
    for attempt in range(5):
        try:
            # Get the response from the OpenAI model
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                            },
                        ],
                    }
                ],
            )
            
            # Extract content from the response
            response_content = response.choices[0].message.content.strip()
            return response_content

        except Exception as e:
            if attempt == 4:  # This is the 5th and final attempt
                print("All attempts failed. Raising the last exception.")
                raise e
            else:
                print(f"Attempt {attempt+1} failed with error: {e}. Retrying...")

# Function to convert the model's response into a JSON-compatible format
import json

def convert_to_json(response):
    # Clean the response to extract JSON content
    cleaned_response = response.strip("```json").strip("```").strip()
    
    # Parse the cleaned response as JSON
    try:
        data = json.loads(cleaned_response)
    except json.JSONDecodeError as e:
        print("Error decoding JSON:", e)
        data = {"Predicted Label": 0, "Reason": "Unable to parse response"}
    
    return data



#%% List of image paths (you can replace this with the actual list of images you want to classify)
# image_paths = [
#     r"images/image_27.567334067381726_-99.50018660409278_0.png",
#     r"images/image_29.905309967680783_-90.08083893088218_0.png",
#     r"images/image_30.34653455325075_-88.48908351525495_1.png",
#     r"images/image_30.774497911656095_-89.86675877587317_0.png",
#     r"images/image_31.579502983475177_-102.96481197450375_0.png",
#     r"images/image_31.768544896983542_-106.39261368091819_1.png",
# ]
import time
import pandas as pd

# Start the timer
start_time = time.time()

# Read image paths from CSV
image_paths = pd.read_csv(r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\Data\test.csv")
image_paths = image_paths["Image_Path"].to_list()

# Initialize a DataFrame to store results
results_df = pd.DataFrame(columns=["Image Name", "Predicted Label", "Reason"])

# Process each image and populate the DataFrame
for image_path in image_paths:
    response = classify_image("C:/Users/panka/OneDrive/Documents/GitHub/llm-oil-gas-vision/Data/" + image_path)
    result_json = convert_to_json(response)

    # Create a temporary DataFrame for the new row
    new_row = pd.DataFrame([{
        "Image Name": image_path,
        "Predicted Label": result_json["Predicted Label"],
        "Reason": result_json["Reason"]
    }])

    # Use pd.concat to add the new row
    results_df = pd.concat([results_df, new_row], ignore_index=True)
    results_df["Image Name"] = results_df["Image Name"].apply(lambda x: x.replace("images/", ""))
    
    # Print the DataFrame
    print(results_df[["Image Name", "Predicted Label"]])

# Save the DataFrame to a CSV file
results_df.to_csv(r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\GPT\GPT_test_predictions.csv", index=False)

# Stop the timer and calculate elapsed time
end_time = time.time()
elapsed_time = end_time - start_time

print(f"\nTotal execution time: {elapsed_time:.2f} seconds")


#%%
# Load the test.csv file

test_df = pd.read_csv(r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\Data\test.csv")
test_df["Image_Path"]=test_df["Image_Path"].apply(lambda x:x.replace("images/",""))

results_df=pd.read_csv(r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\GPT\GPT_test_predictions.csv")

# Merge the two dataframes on 'Image Name' to add the 'Actual Label' column
merged_df = results_df.merge(test_df[['Image_Path', 'Target']], 
                                     left_on='Image Name', 
                                     right_on='Image_Path', 
                                     how='left')

# Drop redundant 'Image_Path' column after merging
merged_df.drop(columns=['Image_Path'], inplace=True)
merged_df.rename(columns={"Target":"Actual Label"},inplace=True)


# Save the merged dataframe
merged_output_path = r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\GPT\GPT_test_predictions.csv"
merged_df.to_csv(merged_output_path, index=False)
merged_df

#%%

#Create a GPT COnfusion Matrices plot
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Load the merged GPT predictions file
file_path = merged_output_path
gpt_results = pd.read_csv(file_path)

# Extract actual labels and predicted labels for GPT
y_true_gpt = gpt_results["Actual Label"]
y_pred_gpt = gpt_results["Predicted Label"]

# Compute confusion matrix
conf_matrix = confusion_matrix(y_true_gpt, y_pred_gpt)

# Define the output file path
output_plot_path = r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\GPT\GPT_confusion_matrix.png"

# Save the confusion matrix plot as a PNG file
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.title("Confusion Matrix for GPT Model")
plt.savefig(output_plot_path, dpi=300, bbox_inches='tight')


#%%

import pandas as pd
import os

# Directory where model results are stored
results_dir = r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results"

# List of models to include
models = [
    "DenseNet121", "ResNet50", "VGG16", "InceptionV3", "MobileNetV2",
    "EfficientNetB0", "NASNetMobile", "Xception", "InceptionResNetV2", "ResNet152V2","GPT"
]

# Initialize a dictionary to store dataframes for each model
model_dfs = {}

# Iterate through each model to load its prediction results
for model in models:
    model_result_path = os.path.join(results_dir, model, f'{model}_test_predictions.csv')
    
    if os.path.exists(model_result_path):
        df = pd.read_csv(model_result_path)
        df.rename(columns={'Predicted Label': f'{model}_Predicted_Label'}, inplace=True)
        model_dfs[model] = df[['Image Name', 'Actual Label', f'{model}_Predicted_Label']]

# Merge all model results into a single DataFrame
if model_dfs:
    # Start with the first model's DataFrame
    combined_results = list(model_dfs.values())[0]

    for model, df in list(model_dfs.items())[1:]:
        combined_results = pd.merge(combined_results, df, on=['Image Name', 'Actual Label'], how='outer')

    # Save the combined results to an Excel file
    combined_results.to_excel(r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\combined_test_classification_results.xlsx", index=False)

combined_results.head()
#%%
import pandas as pd
from sklearn.metrics import f1_score

# Load the combined test classification results
file_path = r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\combined_test_classification_results.xlsx"
df = pd.read_excel(file_path)
df=df.dropna()
df.reset_index(inplace=True)

# Extract actual labels
y_true = df["Actual Label"].values

# Calculate F1 scores for each model
f1_scores = {}
for column in df.columns:
    if "Predicted_Label" in column:
        model_name = column.replace("_Predicted_Label", "")
        y_pred = df[column].values
        f1_scores[model_name] = f1_score(y_true, y_pred, average="binary")

# Convert results into a DataFrame for better visualization
f1_scores_df = pd.DataFrame(list(f1_scores.items()), columns=["Model", "F1 Score"])
f1_scores_df = f1_scores_df.sort_values(by="F1 Score", ascending=False)

f1_scores_df

#%%
f1_scores_df.to_csv(r"C:\Users\panka\OneDrive\Documents\GitHub\llm-oil-gas-vision\results\combined_f1_score.csv",index=False)
#%%

#Plot the confusion matrices side by side -

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Extract actual labels and predictions for the top 3 models
y_true = df["Actual Label"]
y_pred_inceptionv3 = df["InceptionV3_Predicted_Label"]
y_pred_gpt = df["GPT_Predicted_Label"]
y_pred_inceptionresnetv2 = df["InceptionResNetV2_Predicted_Label"]

# Compute confusion matrices
cm_inceptionv3 = confusion_matrix(y_true, y_pred_inceptionv3)
cm_gpt = confusion_matrix(y_true, y_pred_gpt)
cm_inceptionresnetv2 = confusion_matrix(y_true, y_pred_inceptionresnetv2)


# Identify the top 4 models based on F1-score
top_models = ["InceptionV3", "GPT_Predicted_Label", "InceptionResNetV2", "DenseNet121_Predicted_Label"]

# Extract actual labels and predictions for the top 4 models
y_pred_densenet = df["DenseNet121_Predicted_Label"]

# Compute confusion matrices for the top 4 models
cm_densenet = confusion_matrix(y_true, y_pred_densenet)

# Update the list of confusion matrices and titles
titles = ["InceptionV3", "GPT-4o-mini", "InceptionResNetV2", "DenseNet121"]
cms = [cm_inceptionv3, cm_gpt, cm_inceptionresnetv2, cm_densenet]

# Plot confusion matrices in a 2x2 grid
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Flatten axes for easy iteration
axes = axes.flatten()

# Plot each confusion matrix
for ax, cm, title in zip(axes, cms, titles):
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"], ax=ax)
    ax.set_title(f"Confusion Matrix - {title}")
    ax.set_xlabel("Predicted Label")
    ax.set_ylabel("Actual Label")

# Adjust layout and show the plot
plt.tight_layout()
plt.show()
